#!/usr/bin/env python
import argparse
import json
import os
import subprocess
import sys
import threading
import time
from datetime import datetime
from pathlib import Path

from flask_cors import CORS
from flask import Flask, jsonify, request
from dotenv import load_dotenv
from mutagen.id3 import ID3

from drivers.spotify_client import sync_to_master_playlist, authenticate_spotify
from helpers.m3u_helper import find_local_file_path
from sql.core.unit_of_work import UnitOfWork

# Load environment variables
load_dotenv()

# Define paths
PROJECT_ROOT = Path(__file__).resolve().parent

# Add project root to Python path for imports
sys.path.insert(0, str(PROJECT_ROOT))

from helpers.file_helper import embed_track_metadata
from helpers.organization_helper import organize_songs_into_m3u_playlists
from helpers.validation_helper import validate_master_tracks
from sql.helpers.db_helper import clear_db, insert_playlists, insert_tracks_and_associations, MASTER_PLAYLIST_ID

app = Flask(__name__)
CORS(app, origins=["https://xpui.app.spotify.com", "https://open.spotify.com", "http://localhost:4000", "*"])
app.config['JSONIFY_PRETTYPRINT_REGULAR'] = True

SCRIPTS_DIR = PROJECT_ROOT / "scripts"
HELPERS_DIR = PROJECT_ROOT / "helpers"

LOCAL_TRACKS_SERVER_PATH = SCRIPTS_DIR / "local_tracks_server.py"
SYNC_LOCAL_TRACKS_PATH = SCRIPTS_DIR / "sync_local_tracks.py"
EMBED_METADATA_SCRIPT = HELPERS_DIR / "file_helper.py"

# Get environment variables
MASTER_TRACKS_DIRECTORY_SSD = os.getenv("MASTER_TRACKS_DIRECTORY_SSD")
LOCAL_TRACKS_CACHE_DIRECTORY = os.getenv("LOCAL_TRACKS_CACHE_DIRECTORY")
MASTER_PLAYLIST_ID = os.getenv("MASTER_PLAYLIST_ID")
DEFAULT_PORT = 8765


@app.route('/')
def get_local_tracks():
    """
    Return the local tracks cache file as JSON.
    This method reads the cache file generated by sync_local_tracks.py
    and returns it to the client.
    """
    try:
        # Default cache file name
        cache_file = "local_tracks_cache.json"

        # Check if we have a specific cache_path from query parameters
        cache_path = request.args.get('cache_path')

        if cache_path and os.path.exists(cache_path):
            # If a specific path was provided and exists, use it
            if os.path.isdir(cache_path):
                # If it's a directory, look for the default cache file inside it
                full_path = os.path.join(cache_path, cache_file)
            else:
                # If it's a file, use it directly
                full_path = cache_path
        elif LOCAL_TRACKS_CACHE_DIRECTORY:
            # Use the environment variable if available
            full_path = os.path.join(LOCAL_TRACKS_CACHE_DIRECTORY, cache_file)
        else:
            # Fallback to a default location relative to the script
            script_dir = Path(__file__).resolve().parent
            full_path = os.path.join(script_dir, "cache", cache_file)

        # Check if the cache file exists
        if not os.path.exists(full_path):
            return jsonify({
                "error": "Cache file not found",
                "message": "Run 'python tagify_integration.py cache' to generate the cache file first."
            }), 404

        # Read the cache file
        with open(full_path, 'r', encoding='utf-8') as f:
            cache_data = json.load(f)

        # Check if the cache data has the expected structure
        if not isinstance(cache_data, dict) or 'tracks' not in cache_data:
            return jsonify({
                "error": "Invalid cache format",
                "message": "The cache file is not in the expected format."
            }), 500

        # Return the cache data
        return jsonify(cache_data)

    except Exception as e:
        return jsonify({
            "error": "Server error",
            "message": str(e)
        }), 500


@app.route('/status')
def get_status():
    return jsonify({
        "status": "running",
        "version": "1.0",
        "env_vars": {
            "MASTER_TRACKS_DIRECTORY_SSD": MASTER_TRACKS_DIRECTORY_SSD,
            "LOCAL_TRACKS_CACHE_DIRECTORY": LOCAL_TRACKS_CACHE_DIRECTORY,
            "MASTER_PLAYLIST_ID": MASTER_PLAYLIST_ID
        }
    })


@app.route('/api/generate-cache', methods=['POST'])
def api_generate_cache():
    try:
        from scripts.sync_local_tracks import generate_cache

        # Get request data with better logging
        request_data = request.get_json()
        print(f"Received request data: {request_data}")

        music_dir = request_data.get('masterTracksDir') if request_data else None
        output_dir = request_data.get('outputDir') if request_data else None

        # Log what we received
        print(f"Music directory from request: {music_dir}")
        print(f"Output directory from request: {output_dir}")

        # Fallback to environment variables if needed
        if not music_dir:
            music_dir = MASTER_TRACKS_DIRECTORY_SSD
            print(f"Using environment variable for music directory: {music_dir}")

        if not output_dir:
            output_dir = LOCAL_TRACKS_CACHE_DIRECTORY
            print(f"Using environment variable for output directory: {output_dir}")

        # Final validation
        if not music_dir:
            return jsonify({
                "success": False,
                "message": "Music directory not specified in request or environment"
            }), 400

        if not output_dir:
            return jsonify({
                "success": False,
                "message": "Output directory not specified in request or environment"
            }), 400

        # Normalize paths (handle backslashes)
        music_dir = os.path.normpath(music_dir)
        output_dir = os.path.normpath(output_dir)

        print(f"Generating cache with music_dir: {music_dir}")
        print(f"Output directory: {output_dir}")

        # Create output directory if it doesn't exist
        os.makedirs(output_dir, exist_ok=True)

        # Now generate the cache
        result = generate_cache(music_dir, output_dir)
        return jsonify({
            "success": True,
            "message": f"Cache generated successfully with {result}",
            "stats": result
        })
    except Exception as e:
        import traceback
        traceback_str = traceback.format_exc()
        print(f"Error in generate-cache: {str(e)}")
        print(traceback_str)
        return jsonify({
            "success": False,
            "message": f"Error: {str(e)}",
            "traceback": traceback_str
        }), 500


@app.route('/api/direct-tracks-compare', methods=['GET'])
def api_direct_tracks_compare():
    """
    Directly compare Spotify tracks with local tracks from the database.
    Returns information about missing tracks without requiring a cache file.
    """
    try:
        # Get master playlist ID (from query param or environment)
        playlist_id = request.args.get('master_playlist_id') or MASTER_PLAYLIST_ID

        if not playlist_id:
            return jsonify({
                "success": False,
                "message": "Master playlist ID not provided"
            }), 400

        # 1. Get all tracks from the master playlist in the database
        with UnitOfWork() as uow:
            master_tracks = uow.track_repository.get_all()

            # Convert to a list of dicts for JSON serialization
            master_tracks_list = []
            for track in master_tracks:
                master_tracks_list.append({
                    'id': track.track_id,
                    'name': track.title,
                    'artists': track.artists,
                    'album': track.album,
                    'added_at': track.added_to_master.isoformat() if track.added_to_master else None
                })

            # 2. Get all local tracks (tracks that have paths associated with them)
            # Create a set of track IDs that are verified to exist locally
            local_track_ids = set()
            local_tracks_info = []

            # Scan the master tracks directory to find which files have TrackIds
            master_tracks_dir = request.args.get('master_tracks_dir') or MASTER_TRACKS_DIRECTORY_SSD

            if not master_tracks_dir or not os.path.exists(master_tracks_dir):
                return jsonify({
                    "success": False,
                    "message": f"Master tracks directory does not exist: {master_tracks_dir}"
                }), 400

            # Scan local files to find which ones have TrackIds embedded
            for root, _, files in os.walk(master_tracks_dir):
                for filename in files:
                    if not filename.lower().endswith('.mp3'):
                        continue

                    file_path = os.path.join(root, filename)

                    # Check if this file has a TrackId
                    try:
                        from mutagen.id3 import ID3, ID3NoHeaderError
                        try:
                            tags = ID3(file_path)
                            if 'TXXX:TRACKID' in tags:
                                track_id = tags['TXXX:TRACKID'].text[0]
                                local_track_ids.add(track_id)
                                local_tracks_info.append({
                                    'path': file_path,
                                    'filename': filename,
                                    'track_id': track_id,
                                    'size': os.path.getsize(file_path),
                                    'modified': os.path.getmtime(file_path)
                                })
                        except ID3NoHeaderError:
                            pass
                    except Exception as e:
                        print(f"Error reading ID3 tags from {file_path}: {e}")

            # 3. Compare to find missing tracks
            missing_tracks = []
            for track in master_tracks_list:
                # Skip tracks without an ID (shouldn't happen but just in case)
                if not track['id']:
                    continue

                # Skip tracks that are local files
                if track['id'].startswith('local_'):
                    continue

                # If track ID is not in local tracks, it's missing
                if track['id'] not in local_track_ids:
                    missing_tracks.append(track)

            # Sort missing tracks by added_at date, newest first
            missing_tracks.sort(
                key=lambda x: x['added_at'] if x['added_at'] else '0',
                reverse=True
            )

            # 4. Return the results
            return jsonify({
                "success": True,
                "database_time": datetime.now().isoformat(),
                "master_tracks": master_tracks_list,
                "local_tracks": {
                    "count": len(local_track_ids),
                    "tracks": local_tracks_info[:100]  # Limit to avoid huge payloads
                },
                "missing_tracks": missing_tracks,
                "music_directory": master_tracks_dir,
                "master_playlist_id": playlist_id
            })

    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error in direct tracks compare: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": str(e),
            "traceback": error_str
        }), 500


@app.route('/api/embed-metadata', methods=['POST'])
def api_embed_metadata():
    master_tracks_dir = request.json.get('masterTracksDir') or MASTER_TRACKS_DIRECTORY_SSD
    confirmed = request.json.get('confirmed', False)
    user_selections = request.json.get('userSelections', [])
    skipped_files = request.json.get('skippedFiles', [])
    auto_confirm_threshold = request.json.get('auto_confirm_threshold', 0.75)

    if not master_tracks_dir:
        return jsonify({
            "success": False,
            "message": "Master tracks directory not specified in request or environment"
        }), 400

    # If we've received confirmation with user selections, actually embed the metadata
    if confirmed and user_selections:
        try:
            successful_embeds = 0
            failed_embeds = 0
            results = []

            for selection in user_selections:
                file_name = selection.get('fileName')
                track_id = selection.get('trackId')
                confidence = selection.get('confidence')

                # Find the full file path
                file_path = None
                for root, _, files in os.walk(master_tracks_dir):
                    if file_name in files:
                        file_path = os.path.join(root, file_name)
                        break

                if file_path and track_id:
                    # Use the embed_track_id function from file_helper.py
                    from helpers.file_helper import embed_track_id
                    success = embed_track_id(file_path, track_id)

                    if success:
                        successful_embeds += 1
                        results.append({
                            "file": file_name,
                            "track_id": track_id,
                            "success": True
                        })
                    else:
                        failed_embeds += 1
                        results.append({
                            "file": file_name,
                            "track_id": track_id,
                            "success": False,
                            "reason": "Failed to write to file"
                        })
                else:
                    failed_embeds += 1
                    results.append({
                        "file": file_name,
                        "track_id": track_id,
                        "success": False,
                        "reason": "File not found or track ID missing"
                    })

            return jsonify({
                "success": True,
                "message": f"Embedded TrackId into {successful_embeds} files. {failed_embeds} files failed.",
                "results": results,
                "successful_embeds": successful_embeds,
                "failed_embeds": failed_embeds,
                "skipped_files": len(skipped_files)
            })

        except Exception as e:
            import traceback
            error_str = traceback.format_exc()
            print(f"Error embedding metadata: {e}")
            print(error_str)
            return jsonify({
                "success": False,
                "message": str(e),
                "traceback": error_str
            }), 500

    # If not confirmed, analyze files that need processing
    try:
        # Get list of all files first without making changes
        all_files = []
        total_files = 0
        files_without_id = []
        auto_matched_files = []

        for root, _, files in os.walk(master_tracks_dir):
            for file in files:
                if not file.lower().endswith('.mp3'):
                    continue

                total_files += 1
                file_path = os.path.join(root, file)

                # Check if file has TrackId
                has_id = False
                try:
                    tags = ID3(file_path)
                    if 'TXXX:TRACKID' in tags:
                        has_id = True
                except Exception:
                    pass

                if not has_id:
                    # Try to find high confidence exact matches
                    exact_match = None
                    with UnitOfWork() as uow:
                        tracks_db = uow.track_repository.get_all()
                        for track in tracks_db:
                            if track.is_local and (track.title == file or track.title == os.path.splitext(file)[0]):
                                # Found exact match
                                exact_match = {
                                    'fileName': file,
                                    'trackId': track.track_id,
                                    'confidence': 1.0  # 100% confidence
                                }
                                break

                    if exact_match and exact_match['confidence'] >= auto_confirm_threshold:
                        # Auto-match this file - embed the TrackId immediately
                        from helpers.file_helper import embed_track_id
                        success = embed_track_id(file_path, exact_match['trackId'])
                        if success:
                            auto_matched_files.append(exact_match)
                        else:
                            # If embedding failed, add to manual process list
                            files_without_id.append(file)
                    else:
                        # No high confidence match, add to manual process list
                        files_without_id.append(file)

        # Return analysis with files that need processing
        return jsonify({
            "success": True,
            "message": f"Found {len(files_without_id)} files without TrackId out of {total_files} total files. Auto-matched {len(auto_matched_files)} files.",
            "needs_confirmation": len(files_without_id) > 0,
            "requires_fuzzy_matching": len(files_without_id) > 0,
            "details": {
                "files_to_process": files_without_id,
                "total_files": total_files,
                "auto_matched_files": auto_matched_files
            }
        })
    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error analyzing metadata embedding: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": str(e),
            "traceback": error_str
        }), 500


@app.route('/api/fuzzy-match-track', methods=['POST'])
def api_fuzzy_match_track():
    try:
        file_name = request.json.get('fileName')
        master_tracks_dir = request.json.get('masterTracksDir') or MASTER_TRACKS_DIRECTORY_SSD

        print(f"Received fuzzy match request for file: {file_name}")
        print(f"Using master tracks dir: {master_tracks_dir}")

        if not file_name:
            return jsonify({"success": False, "message": "No file name provided"}), 400

        # Load tracks from database for matching
        with UnitOfWork() as uow:
            try:
                tracks_db = uow.track_repository.get_all()
                print(f"Successfully loaded {len(tracks_db)} tracks from database")
            except Exception as e:
                print(f"Database error: {e}")
                return jsonify({"success": False, "message": f"Database error: {str(e)}"}), 500

        # DIRECT MATCH FOR LOCAL FILES - First try an exact file name match
        exact_file_matches = []
        for track in tracks_db:
            if track.is_local:
                # Compare the file name directly
                if track.title == file_name or track.title == os.path.splitext(file_name)[0]:
                    # Exact file name match - give this highest priority
                    exact_file_matches.append({
                        'track_id': track.track_id,
                        'ratio': 1.0,  # Perfect match
                        'artist': track.artists or "",
                        'title': track.title,
                        'album': track.album or "Local Files",
                        'is_local': True,
                        'match_type': 'exact_file'
                    })
                    print(f"Found EXACT file name match: {track.title}")

        # If we found exact matches, return them immediately
        if exact_file_matches:
            print(f"Returning {len(exact_file_matches)} exact file matches for {file_name}")
            return jsonify({
                "success": True,
                "file_name": file_name,
                "original_artist": "",
                "original_title": os.path.splitext(file_name)[0],
                "matches": exact_file_matches
            })

        # Extract artist and title from filename
        try:
            name_part = os.path.splitext(file_name)[0]

            # Try standard "Artist - Title" format first
            if " - " in name_part:
                artist, track_title = name_part.split(" - ", 1)
            else:
                # Handle files without the separator
                artist = ""
                track_title = name_part
                print(f"NOTE: '{file_name}' doesn't follow 'Artist - Title' format. Will try to match by title only.")
        except ValueError:
            print(f"Filename format issue: {file_name}")
            artist = ""
            track_title = name_part

        # Normalize for comparison
        normalized_artist = artist.lower().replace('&', 'and')
        normalized_title = track_title.lower()

        # Original artist and title for display
        original_artist = artist
        original_title = track_title

        # Handle remix information
        remix_info = ""
        if "remix" in normalized_title.lower():
            remix_parts = normalized_title.lower().split("remix")
            normalized_title = remix_parts[0].strip()
            remix_info = "remix" + remix_parts[1] if len(remix_parts) > 1 else "remix"

        # Calculate matches
        matches = []
        print(f"Calculating fuzzy matches for '{file_name}'")

        # IMPORTANT: First, check for matching local files - Add this block
        local_tracks = [track for track in tracks_db if track.is_local]
        print(f"Found {len(local_tracks)} local tracks in database")

        # Try to match against local files first
        for track in local_tracks:
            # For local files, just compare titles since they might not have proper artist-title format
            db_title = track.title.lower()

            # Normalize both titles
            import re
            clean_normalized_title = re.sub(r'[\(\[].*?[\)\]]', '', normalized_title).strip()
            db_title_clean = re.sub(r'[\(\[].*?[\)\]]', '', db_title).strip()

            # Calculate similarity
            import Levenshtein
            similarity = Levenshtein.ratio(clean_normalized_title, db_title_clean)

            # Add high similarity boost for exact file name match
            if clean_normalized_title == db_title_clean or file_name.lower() == track.title.lower():
                similarity = 1.0

            # Include if reasonable match
            if similarity >= 0.5:
                matches.append({
                    'track_id': track.track_id,
                    'ratio': similarity,
                    'artist': track.artists or "Local File",
                    'title': track.title,
                    'album': track.album or "Local Files",
                    'is_local': True
                })

        # Then process regular Spotify tracks
        for track in tracks_db:
            # Skip local files as we already processed them
            if track.is_local:
                continue

            # Process artists and titles - rest of your existing matching logic
            db_artists = track.artists.lower().replace('&', 'and')
            db_title = track.title.lower()
            track_id = track.track_id

            # Split artists and normalize
            db_artist_list = [a.strip() for a in db_artists.split(',')]
            expanded_artists = []
            for db_artist in db_artist_list:
                if ' and ' in db_artist:
                    expanded_artists.extend([a.strip() for a in db_artist.split(' and ')])
                else:
                    expanded_artists.append(db_artist)

            # Artist match calculation
            artist_ratios = []
            if artist:  # Only do artist matching if we have an artist name
                artist_ratios = [Levenshtein.ratio(normalized_artist, db_artist) for db_artist in expanded_artists]
                artist_ratio = max(artist_ratios) if artist_ratios else 0

                # Perfect match bonus
                if any(normalized_artist == db_artist for db_artist in expanded_artists):
                    artist_ratio = 1.0
            else:
                artist_ratio = 0.0

            # Clean titles for better matching
            import re
            clean_normalized_title = re.sub(r'[\(\[].*?[\)\]]', '', normalized_title).strip()
            db_title_clean = re.sub(r'[\(\[].*?[\)\]]', '', db_title).strip()

            # Create title variations for matching
            title_variations = [
                db_title,
                db_title_clean,
                db_title.replace(' - ', ' ').replace("'s", "s")
            ]

            # Find best title match
            title_ratios = [Levenshtein.ratio(clean_normalized_title, var) for var in title_variations]
            title_ratio = max(title_ratios)

            # Perfect match bonus
            if clean_normalized_title in [var.lower() for var in title_variations]:
                title_ratio = 1.0

            # Remix bonus
            remix_bonus = 0
            if any(x in track_title.lower() for x in ['remix', 'edit', 'mix', 'version']) and \
                    any(x in db_title for x in ['remix', 'edit', 'mix', 'version']):
                remix_bonus = 0.1

                # Extra bonus for same remixer
                remix_pattern = r'\(([^)]+)(remix|edit|version|mix)\)'
                local_remix_match = re.search(remix_pattern, track_title.lower())
                db_remix_match = re.search(remix_pattern, db_title.lower())

                if local_remix_match and db_remix_match and local_remix_match.group(1) == db_remix_match.group(1):
                    remix_bonus += 0.1

            # Calculate overall match score
            if artist:
                overall_ratio = (artist_ratio * 0.6 + title_ratio * 0.3 + remix_bonus)
            else:
                overall_ratio = (title_ratio * 0.9 + remix_bonus)

            # Return if over threshold
            if overall_ratio >= 0.45:  # Lower threshold for showing more options
                matches.append({
                    'track_id': track_id,
                    'ratio': overall_ratio,
                    'artist': track.artists,
                    'title': track.title,
                    'album': track.album,
                    'is_local': False
                })

        # Sort by match quality
        matches.sort(key=lambda x: x['ratio'], reverse=True)

        # Limit to top 8 matches
        top_matches = matches[:8]

        print(f"Found {len(top_matches)} potential matches for '{file_name}'")

        # Return the original file info and potential matches
        print(f"Returning {len(top_matches)} matches for {file_name}")
        return jsonify({
            "success": True,
            "file_name": file_name,
            "original_artist": original_artist,
            "original_title": original_title,
            "matches": top_matches
        })
    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error in fuzzy match: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": str(e),
            "traceback": error_str
        }), 500


@app.route('/api/generate-m3u', methods=['POST'])
def api_generate_m3u():
    data = request.json
    master_tracks_dir = data.get('masterTracksDir') or MASTER_TRACKS_DIRECTORY_SSD
    playlists_dir = data.get('playlistsDir')

    if not master_tracks_dir:
        return jsonify({
            "success": False,
            "message": "Master tracks directory not specified in request or environment"
        }), 400

    if not playlists_dir:
        return jsonify({
            "success": False,
            "message": "Playlists directory not specified in request"
        }), 400

    try:
        # First, analyze what will be generated
        with UnitOfWork() as uow:
            db_playlists = uow.playlist_repository.get_all()

        # Filter out the MASTER playlist if it exists
        db_playlists = [p for p in db_playlists if p.name.upper() != "MASTER"]

        # Get track counts for each playlist for display
        playlist_stats = []
        for playlist in db_playlists:
            with UnitOfWork() as uow:
                tracks = uow.track_playlist_repository.get_track_ids_for_playlist(playlist.playlist_id)
                track_count = len(tracks)
                playlist_stats.append({
                    'name': playlist.name,
                    'track_count': track_count,
                    'id': playlist.playlist_id
                })

        # Sort playlists by track count (descending)
        playlist_stats.sort(key=lambda x: x['track_count'], reverse=True)

        # Return analysis without making changes
        return jsonify({
            "success": True,
            "message": f"Ready to generate {len(playlist_stats)} M3U playlists.",
            "needs_confirmation": len(playlist_stats) > 0,
            "details": {
                "playlists": playlist_stats,
                "total_playlists": len(playlist_stats),
                "playlists_with_tracks": sum(1 for p in playlist_stats if p['track_count'] > 0)
            }
        })
    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error analyzing M3U generation: {e}")
        print(error_str)
        return jsonify({"success": False, "message": str(e)}), 500


@app.route('/api/validate-tracks', methods=['POST'])
def api_validate_tracks():
    master_tracks_dir = request.json.get('masterTracksDir')

    try:
        result = validate_master_tracks(master_tracks_dir)
        return jsonify({"success": True, "stats": result})
    except Exception as e:
        return jsonify({"success": False, "message": str(e)}), 500


@app.route('/api/sync-to-master', methods=['POST'])
def api_sync_to_master():
    try:
        # Import the function with the fixed implementation
        from drivers.spotify_client import sync_to_master_playlist, authenticate_spotify

        # Get the master playlist ID
        master_playlist_id = request.json.get('master_playlist_id')
        if not master_playlist_id:
            master_playlist_id = MASTER_PLAYLIST_ID

        if not master_playlist_id:
            return jsonify({
                "success": False,
                "message": "Master playlist ID not provided or found in environment"
            }), 400

        spotify_client = authenticate_spotify()

        # This is a long-running operation, so respond immediately
        response = {
            "success": True,
            "message": "Sync to master playlist started. This operation runs in the background and may take several minutes."
        }

        def background_sync():
            try:
                # Use the fixed function
                sync_to_master_playlist(spotify_client, master_playlist_id)
            except Exception as e:
                import traceback
                error_str = traceback.format_exc()
                print(f"Error in background sync: {e}")
                print(error_str)

        thread = threading.Thread(target=background_sync)
        thread.daemon = True
        thread.start()

        return jsonify(response)

    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error starting sync: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": f"Error: {str(e)}"
        }), 500


@app.route('/api/analyze-master-sync', methods=['POST'])
def api_analyze_master_sync():
    try:
        # Import required functions
        from drivers.spotify_client import authenticate_spotify, get_playlist_track_ids

        master_playlist_id = request.json.get('master_playlist_id') or MASTER_PLAYLIST_ID
        if not master_playlist_id:
            return jsonify({
                "success": False,
                "message": "Master playlist ID not provided or found in environment"
            }), 400

        # Authenticate and start analysis
        spotify_client = authenticate_spotify()

        # This is a simplified version of sync_to_master_playlist that just analyzes

        # Get current tracks in MASTER playlist
        master_track_ids = set(get_playlist_track_ids(spotify_client, master_playlist_id, force_refresh=True))

        # Fetch all playlists (excluding forbidden ones)
        from drivers.spotify_client import fetch_playlists
        user_playlists = fetch_playlists(spotify_client, force_refresh=True)

        # Filter playlists safely
        other_playlists = []
        for pl in user_playlists:
            if isinstance(pl, tuple):
                playlist_name = pl[0] if len(pl) > 0 else "Unknown"

                if len(pl) == 2:
                    playlist_id = pl[1]
                elif len(pl) >= 3:
                    playlist_id = pl[2]
                else:
                    continue

                if playlist_id != master_playlist_id:
                    other_playlists.append((playlist_name, playlist_id))

        # Track which songs come from which playlists
        new_tracks_by_playlist = {}

        # Process each playlist
        for playlist_name, playlist_id in other_playlists:
            # Get tracks for this playlist
            playlist_track_ids = get_playlist_track_ids(spotify_client, playlist_id, force_refresh=True)

            # Filter out local files and find tracks not in master
            new_track_ids = []
            for track_id in playlist_track_ids:
                if track_id.startswith('spotify:local:') or track_id.startswith('local_'):
                    continue

                if track_id not in master_track_ids:
                    new_track_ids.append(track_id)

            if not new_track_ids:
                continue

            # Get track details
            playlist_tracks = []
            for j in range(0, len(new_track_ids), 50):
                batch = new_track_ids[j:j + 50]
                try:
                    tracks_info = spotify_client.tracks(batch)
                    for track in tracks_info['tracks']:
                        if track:
                            track_info = {
                                'id': track['id'],
                                'name': track['name'],
                                'artists': ', '.join(artist['name'] for artist in track['artists'])
                            }
                            playlist_tracks.append(track_info)
                except Exception as e:
                    print(f"Error fetching details for track batch: {e}")
                    continue

            if playlist_tracks:
                new_tracks_by_playlist[playlist_name] = playlist_tracks

        # Calculate statistics
        total_tracks = sum(len(tracks) for tracks in new_tracks_by_playlist.values())

        # Include ALL playlists with ALL tracks
        full_playlists = []
        for playlist_name, tracks in sorted(new_tracks_by_playlist.items()):
            sorted_tracks = sorted(tracks, key=lambda x: (x['artists'], x['name']))
            full_playlists.append({
                'name': playlist_name,
                'track_count': len(tracks),
                'tracks': sorted_tracks  # Include ALL tracks
            })

        # Create analysis result
        analysis = {
            'total_tracks_to_add': total_tracks,
            'playlists_with_new_tracks': len(new_tracks_by_playlist),
            'playlists': full_playlists,  # Full list with all tracks
            'needs_confirmation': total_tracks > 0
        }

        return jsonify({
            "success": True,
            "message": f"Analysis complete: {total_tracks} tracks to add from {len(new_tracks_by_playlist)} playlists",
            "master_sync": analysis,
            "needs_confirmation": total_tracks > 0
        })

    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error analyzing master sync: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": f"Error: {str(e)}",
            "traceback": error_str
        }), 500


@app.route('/api/analyze-playlists', methods=['POST'])
def api_analyze_playlists():
    try:
        from helpers.sync_helper import analyze_playlists_changes

        force_refresh = request.json.get('force_refresh', False)

        # Get analysis without executing
        added_count, updated_count, unchanged_count, changes_details = analyze_playlists_changes(
            force_full_refresh=force_refresh
        )

        return jsonify({
            "success": True,
            "message": f"Analysis complete: {added_count} to add, {updated_count} to update, {unchanged_count} unchanged",
            "stats": {
                "added": added_count,
                "updated": updated_count,
                "unchanged": unchanged_count
            },
            "details": {
                "to_add": changes_details['to_add'],
                "to_update": changes_details['to_update']
            },
            "needs_confirmation": added_count > 0 or updated_count > 0
        })
    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error analyzing playlists: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": f"Error: {str(e)}",
            "traceback": error_str
        }), 500


@app.route('/api/analyze-tracks', methods=['POST'])
def api_analyze_tracks():
    try:
        from helpers.sync_helper import analyze_tracks_changes

        master_playlist_id = request.json.get('master_playlist_id') or MASTER_PLAYLIST_ID
        force_refresh = request.json.get('force_refresh', False)

        # Get analysis without executing
        tracks_to_add, tracks_to_update, unchanged_tracks = analyze_tracks_changes(
            master_playlist_id,
            force_full_refresh=force_refresh
        )

        # Include ALL tracks for display
        all_tracks_to_add = []
        for track in tracks_to_add:
            all_tracks_to_add.append({
                "id": track['id'],
                "title": track['title'],
                "artists": track['artists'],
                "album": track['album'],
                "is_local": track.get('is_local', False)
            })

        all_tracks_to_update = []
        for track in tracks_to_update:
            all_tracks_to_update.append({
                "id": track['id'],
                "old_title": track['old_title'],
                "new_title": track['title'],
                "old_artists": track['old_artists'],
                "new_artists": track['artists'],
                "old_album": track['old_album'],
                "new_album": track['album'],
                "is_local": track.get('is_local', False)
            })

        return jsonify({
            "success": True,
            "message": f"Analysis complete: {len(tracks_to_add)} to add, {len(tracks_to_update)} to update, {len(unchanged_tracks)} unchanged",
            "stats": {
                "added": len(tracks_to_add),
                "updated": len(tracks_to_update),
                "unchanged": len(unchanged_tracks)
            },
            "details": {
                "all_items_to_add": all_tracks_to_add,  # Full list for pagination
                "to_add": all_tracks_to_add[:20],  # First 20 for immediate display
                "to_add_total": len(tracks_to_add),
                "all_items_to_update": all_tracks_to_update,  # Full list for pagination
                "to_update": all_tracks_to_update[:20],  # First 20 for immediate display
                "to_update_total": len(tracks_to_update)
            },
            "needs_confirmation": len(tracks_to_add) > 0 or len(tracks_to_update) > 0
        })
    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error analyzing tracks: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": f"Error: {str(e)}",
            "traceback": error_str
        }), 500


@app.route('/api/analyze-associations', methods=['POST'])
def api_analyze_associations():
    try:
        # Import the analysis function
        from helpers.sync_helper import analyze_track_playlist_associations

        master_playlist_id = request.json.get('master_playlist_id') or MASTER_PLAYLIST_ID
        force_refresh = request.json.get('force_refresh', False)

        # Get the analysis results
        changes = analyze_track_playlist_associations(
            master_playlist_id,
            force_full_refresh=force_refresh
        )

        # Make sure we include all the data needed for the UI
        formatted_changes = {
            "tracks_with_changes": changes['tracks_with_changes'],
            "associations_to_add": changes['associations_to_add'],
            "associations_to_remove": changes['associations_to_remove'],
            "samples": changes['samples'],
            "all_changes": changes.get('all_changes', changes['samples'])  # Use all_changes if available
        }

        return jsonify({
            "success": True,
            "message": f"Analysis complete: {changes['associations_to_add']} to add, {changes['associations_to_remove']} to remove, affecting {len(changes['tracks_with_changes'])} tracks",
            "stats": changes['stats'],
            "details": formatted_changes,
            "needs_confirmation": changes['associations_to_add'] > 0 or changes['associations_to_remove'] > 0
        })
    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error analyzing associations: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": f"Error: {str(e)}",
            "traceback": error_str
        }), 500


@app.route('/api/sync-database', methods=['POST'])
def api_sync_database():
    from helpers.sync_helper import (
        sync_playlists_incremental,
        sync_master_tracks_incremental,
        sync_track_playlist_associations
    )

    data = request.json
    action = data.get('action', 'all')
    force_refresh = data.get('force_refresh', False)
    is_confirmed = data.get('confirmed', False)

    try:
        if action == 'clear':
            from sql.helpers.db_helper import clear_db
            clear_db()
            return jsonify({"success": True, "message": "Database cleared successfully"})

        elif action == 'playlists':
            # If not confirmed, return the analysis result instead
            if not is_confirmed:
                # Call analyze endpoint and return that result
                from flask import redirect
                return redirect('/api/analyze-playlists', code=307)  # 307 preserves POST method

            # Otherwise, proceed with execution
            added, updated, unchanged = sync_playlists_incremental(
                force_full_refresh=force_refresh,
                auto_confirm=True  # Skip confirmation prompt in the function
            )
            return jsonify({
                "success": True,
                "message": f"Playlists synced: {added} added, {updated} updated, {unchanged} unchanged",
                "stats": {
                    "added": added,
                    "updated": updated,
                    "unchanged": unchanged
                }
            })

        elif action == 'tracks':
            # If not confirmed, return the analysis result instead
            if not is_confirmed:
                # Call analyze endpoint and return that result
                from flask import redirect
                return redirect('/api/analyze-tracks', code=307)

            # Otherwise, proceed with execution
            master_playlist_id = data.get('master_playlist_id') or MASTER_PLAYLIST_ID
            added, updated, unchanged = sync_master_tracks_incremental(
                master_playlist_id,
                force_full_refresh=force_refresh,
                auto_confirm=True
            )
            return jsonify({
                "success": True,
                "message": f"Tracks synced: {added} added, {updated} updated, {unchanged} unchanged",
                "stats": {
                    "added": added,
                    "updated": updated,
                    "unchanged": unchanged
                }
            })

        elif action == 'associations':
            # If not confirmed, return the analysis result instead
            if not is_confirmed:
                # Call analyze endpoint and return that result
                from flask import redirect
                return redirect('/api/analyze-associations', code=307)

            # Otherwise, proceed with execution
            master_playlist_id = data.get('master_playlist_id') or MASTER_PLAYLIST_ID
            precomputed_changes = data.get('precomputed_changes')
            stats = sync_track_playlist_associations(
                master_playlist_id,
                force_full_refresh=force_refresh,
                auto_confirm=True,
                precomputed_changes=precomputed_changes
            )
            return jsonify({
                "success": True,
                "message": f"Associations synced: {stats['associations_added']} added, {stats['associations_removed']} removed",
                "stats": stats
            })

        elif action == 'all':
            # For 'all', we'll use a different approach - analyze in sequence and return all results
            if not is_confirmed:
                # Analyze all operations
                master_playlist_id = data.get('master_playlist_id') or MASTER_PLAYLIST_ID

                # 1. Analyze playlists
                from helpers.sync_helper import analyze_playlists_changes
                playlists_added, playlists_updated, playlists_unchanged, playlists_details = analyze_playlists_changes(
                    force_full_refresh=force_refresh
                )

                # 2. Analyze tracks
                from helpers.sync_helper import analyze_tracks_changes
                tracks_to_add, tracks_to_update, tracks_unchanged = analyze_tracks_changes(
                    master_playlist_id,
                    force_full_refresh=force_refresh
                )

                # Format tracks for display - ALL tracks, not just samples
                all_tracks_to_add = []
                for track in tracks_to_add:
                    all_tracks_to_add.append({
                        "artists": track['artists'],
                        "title": track['title'],
                        "is_local": track.get('is_local', False)
                    })

                all_tracks_to_update = []
                for track in tracks_to_update:
                    all_tracks_to_update.append({
                        "old_artists": track['old_artists'],
                        "old_title": track['old_title'],
                        "artists": track['artists'],
                        "title": track['title'],
                        "is_local": track.get('is_local', False)
                    })

                # 3. Analyze associations
                from helpers.sync_helper import analyze_track_playlist_associations
                associations_changes = analyze_track_playlist_associations(
                    master_playlist_id,
                    force_full_refresh=force_refresh
                )

                # Prepare the complete analysis result with FULL data
                all_analyses = {
                    "playlists": {
                        "added": playlists_added,
                        "updated": playlists_updated,
                        "unchanged": playlists_unchanged,
                        "details": playlists_details  # Already has full lists
                    },
                    "tracks": {
                        "added": len(tracks_to_add),
                        "updated": len(tracks_to_update),
                        "unchanged": len(tracks_unchanged),
                        "to_add_sample": all_tracks_to_add[:20],  # First 20 for immediate display
                        "all_tracks_to_add": all_tracks_to_add,  # Full list for pagination
                        "to_add_total": len(tracks_to_add),
                        "to_update_sample": all_tracks_to_update[:20],  # First 20 for immediate display
                        "all_tracks_to_update": all_tracks_to_update,  # Full list for pagination
                        "to_update_total": len(tracks_to_update)
                    },
                    "associations": {
                        **associations_changes,
                        "all_changes": associations_changes.get("tracks_with_changes", [])  # Full list of changes
                    }
                }

                # Determine if we need confirmation
                needs_confirmation = (
                        playlists_added > 0 or
                        playlists_updated > 0 or
                        len(tracks_to_add) > 0 or
                        len(tracks_to_update) > 0 or
                        associations_changes['associations_to_add'] > 0 or
                        associations_changes['associations_to_remove'] > 0
                )

                return jsonify({
                    "success": True,
                    "message": "Analysis complete",
                    "analyses": all_analyses,
                    "needs_confirmation": needs_confirmation
                })

            # Handle the execution case for 'all' when confirmed
            # Add execution code here for when action='all' and is_confirmed=True
            # For now, let's return a message that this isn't implemented yet
            return jsonify({
                "success": False,
                "message": "Confirmation execution for 'all' action not implemented yet"
            })

        else:
            return jsonify({"success": False, "message": "Invalid action"}), 400
    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error in sync_database: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": f"Error: {str(e)}",
            "traceback": error_str
        }), 500


@app.route('/api/validate-track-metadata', methods=['POST'])
def api_validate_track_metadata():
    try:
        # Get parameters from request
        master_tracks_dir = request.json.get('masterTracksDir') or MASTER_TRACKS_DIRECTORY_SSD
        confidence_threshold = request.json.get('confidence_threshold', 0.75)

        if not master_tracks_dir:
            return jsonify({
                "success": False,
                "message": "Master tracks directory not specified"
            }), 400

        # Track statistics
        total_files = 0
        files_with_track_id = 0
        files_without_track_id = 0
        potential_mismatches = []
        duplicate_track_ids = {}

        # Get all tracks from database for comparison
        with UnitOfWork() as uow:
            db_tracks = uow.track_repository.get_all()
            db_tracks_by_id = {track.track_id: track for track in db_tracks}

        # Create a map of IDs to expected filenames for comparison
        expected_filenames = {}
        for track_id, track in db_tracks_by_id.items():
            artist = track.get_primary_artist()
            title = track.title
            expected_filename = f"{artist} - {title}"
            expected_filenames[track_id] = expected_filename.lower()

        # Scan local files
        for root, _, files in os.walk(master_tracks_dir):
            for file in files:
                if not file.lower().endswith('.mp3'):
                    continue

                total_files += 1
                file_path = os.path.join(root, file)
                filename_no_ext = os.path.splitext(file)[0].lower()

                try:
                    tags = ID3(file_path)
                    if 'TXXX:TRACKID' in tags:
                        track_id = tags['TXXX:TRACKID'].text[0]
                        files_with_track_id += 1

                        # Add to duplicate detection
                        if track_id in duplicate_track_ids:
                            duplicate_track_ids[track_id].append(file)
                        else:
                            duplicate_track_ids[track_id] = [file]

                        # Check if track_id exists in database
                        if track_id in db_tracks_by_id:
                            db_track = db_tracks_by_id[track_id]
                            expected_filename = expected_filenames[track_id]

                            # Calculate filename similarity
                            import Levenshtein
                            similarity = Levenshtein.ratio(filename_no_ext, expected_filename)

                            # Flag potential mismatches
                            if similarity < confidence_threshold:
                                potential_mismatches.append({
                                    'file': file,
                                    'track_id': track_id,
                                    'embedded_artist_title': f"{db_track.artists} - {db_track.title}",
                                    'filename': filename_no_ext,
                                    'confidence': similarity,
                                    'full_path': file_path
                                })
                        else:
                            # Track ID not found in database
                            potential_mismatches.append({
                                'file': file,
                                'track_id': track_id,
                                'embedded_artist_title': "Unknown (TrackId not in database)",
                                'filename': filename_no_ext,
                                'confidence': 0,
                                'full_path': file_path,
                                'reason': 'track_id_not_in_db'
                            })
                    else:
                        files_without_track_id += 1
                except Exception as e:
                    files_without_track_id += 1

        # Filter duplicate_track_ids to only include actual duplicates
        real_duplicates = {k: v for k, v in duplicate_track_ids.items() if len(v) > 1}

        # Sort potential mismatches by confidence
        potential_mismatches.sort(key=lambda x: x['confidence'])

        return jsonify({
            "success": True,
            "summary": {
                "total_files": total_files,
                "files_with_track_id": files_with_track_id,
                "files_without_track_id": files_without_track_id,
                "potential_mismatches": len(potential_mismatches),
                "duplicate_track_ids": len(real_duplicates)
            },
            "potential_mismatches": potential_mismatches,
            "duplicate_track_ids": real_duplicates
        })
    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error validating track metadata: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": str(e),
            "traceback": error_str
        }), 500


@app.route('/api/validate-playlists', methods=['POST'])
def api_validate_playlists():
    try:
        # Get parameters from request
        master_tracks_dir = request.json.get('masterTracksDir') or MASTER_TRACKS_DIRECTORY_SSD
        playlists_dir = request.json.get('playlistsDir')

        if not master_tracks_dir:
            return jsonify({
                "success": False,
                "message": "Master tracks directory not specified"
            }), 400

        if not playlists_dir:
            return jsonify({
                "success": False,
                "message": "Playlists directory not specified"
            }), 400

        # Build track ID mapping first for efficiency
        from helpers.m3u_helper import build_track_id_mapping
        track_id_map = build_track_id_mapping(master_tracks_dir)

        # Get all playlists from database
        with UnitOfWork() as uow:
            db_playlists = uow.playlist_repository.get_all()
            # Filter out the MASTER playlist
            db_playlists = [p for p in db_playlists if p.name.upper() != "MASTER"]

        # Analyze each playlist's integrity
        playlist_analysis = []

        for playlist in db_playlists:
            playlist_name = playlist.name
            playlist_id = playlist.playlist_id

            # Check if this playlist has an M3U file
            from helpers.m3u_helper import sanitize_filename
            safe_name = sanitize_filename(playlist_name, preserve_spaces=True)
            m3u_path = os.path.join(playlists_dir, f"{safe_name}.m3u")

            # Get all track-playlist associations from the database
            with UnitOfWork() as uow:
                all_track_ids_in_playlist = set(uow.track_playlist_repository.get_track_ids_for_playlist(playlist_id))
                expected_tracks = []

                # Get details for all tracks in the playlist
                for track_id in all_track_ids_in_playlist:
                    track = uow.track_repository.get_by_id(track_id)
                    if track:
                        expected_tracks.append({
                            'id': track_id,
                            'title': track.title,
                            'artists': track.artists,
                            'album': track.album or '',
                            'is_local': track.is_local
                        })

            # Track which database IDs actually exist locally
            local_track_files = set()

            # For Spotify tracks (non-local), check the track_id_map
            for track_id in all_track_ids_in_playlist:
                if not track_id.startswith('local_'):
                    if track_id in track_id_map:
                        local_track_files.add(track_id)
                else:
                    # For local tracks, we need to find them by name
                    with UnitOfWork() as uow:
                        track = uow.track_repository.get_by_id(track_id)
                        if track:
                            # Search for the file by artist/title
                            from helpers.m3u_helper import find_local_file_path
                            local_path = find_local_file_path(track.title, track.artists, master_tracks_dir)
                            if local_path:
                                local_track_files.add(track_id)

            # Process M3U file if it exists
            if os.path.exists(m3u_path):
                # Get tracks in the M3U file
                from helpers.m3u_helper import get_m3u_track_ids
                m3u_track_ids = get_m3u_track_ids(m3u_path, track_id_map)

                # These are tracks that should be in the M3U but aren't
                missing_track_ids = local_track_files - m3u_track_ids

                # These are tracks in the M3U that shouldn't be there
                unexpected_track_ids = m3u_track_ids - all_track_ids_in_playlist

                # Get details for missing tracks
                missing_tracks = []
                for track_id in missing_track_ids:
                    with UnitOfWork() as uow:
                        track = uow.track_repository.get_by_id(track_id)
                        if track:
                            missing_tracks.append({
                                'id': track_id,
                                'title': track.title,
                                'artists': track.artists,
                                'album': track.album or '',
                                'is_local': track.is_local
                            })

                # Get details for unexpected tracks
                unexpected_tracks = []
                for track_id in unexpected_track_ids:
                    with UnitOfWork() as uow:
                        track = uow.track_repository.get_by_id(track_id)
                        if track:
                            unexpected_tracks.append({
                                'id': track_id,
                                'title': track.title,
                                'artists': track.artists,
                                'album': track.album or '',
                                'is_local': track.is_local
                            })

                # Calculate the total discrepancy
                # This counts both identified missing/unexpected tracks AND any other track count discrepancies
                total_discrepancy = len(all_track_ids_in_playlist) - len(m3u_track_ids)
                identified_discrepancy = len(missing_track_ids) + len(unexpected_track_ids)
                unidentified_discrepancy = abs(total_discrepancy) - identified_discrepancy

                # The playlist needs an update if there's any discrepancy whatsoever
                needs_update = (len(missing_tracks) > 0 or
                                len(unexpected_tracks) > 0 or
                                len(local_track_files) != len(m3u_track_ids) or
                                abs(total_discrepancy) > 0)

                # Debug logging
                print(f"Playlist: {playlist_name}")
                print(f"  - All track-playlist associations: {len(all_track_ids_in_playlist)}")
                print(f"  - Tracks with local files: {len(local_track_files)}")
                print(f"  - Tracks in M3U: {len(m3u_track_ids)}")
                print(f"  - Missing tracks identified: {len(missing_tracks)}")
                print(f"  - Unexpected tracks: {len(unexpected_tracks)}")
                print(f"  - Total discrepancy: {total_discrepancy}")
                print(f"  - Unidentified discrepancy: {unidentified_discrepancy}")
                print(f"  - Needs update: {needs_update}")

                playlist_analysis.append({
                    'name': playlist_name,
                    'id': playlist_id,
                    'has_m3u': True,
                    'needs_update': needs_update,
                    'total_associations': len(all_track_ids_in_playlist),
                    'tracks_with_local_files': len(local_track_files),
                    'm3u_track_count': len(m3u_track_ids),
                    'tracks_missing_from_m3u': missing_tracks,
                    'unexpected_tracks_in_m3u': unexpected_tracks,
                    'total_discrepancy': total_discrepancy,
                    'unidentified_discrepancy': unidentified_discrepancy
                })
            else:
                # M3U file doesn't exist - definitely needs an update
                playlist_analysis.append({
                    'name': playlist_name,
                    'id': playlist_id,
                    'has_m3u': False,
                    'needs_update': True,
                    'total_associations': len(all_track_ids_in_playlist),
                    'tracks_with_local_files': len(local_track_files),
                    'm3u_track_count': 0,
                    'tracks_missing_from_m3u': expected_tracks,
                    'unexpected_tracks_in_m3u': [],
                    'total_discrepancy': len(all_track_ids_in_playlist),
                    'unidentified_discrepancy': 0
                })

        # Count playlists needing updates
        playlists_needing_update = sum(1 for p in playlist_analysis if p['needs_update'])
        missing_m3u_files = sum(1 for p in playlist_analysis if not p['has_m3u'])

        # Sort by issue severity
        playlist_analysis.sort(key=lambda x: (
            not x['has_m3u'],  # Missing M3U files first
            abs(x['total_discrepancy']),  # Then by total discrepancy
            len(x['tracks_missing_from_m3u']) + len(x['unexpected_tracks_in_m3u']),
            # Then by number of identified issues
            x['name']  # Then alphabetically
        ), reverse=True)

        return jsonify({
            "success": True,
            "summary": {
                "total_playlists": len(playlist_analysis),
                "playlists_needing_update": playlists_needing_update,
                "missing_m3u_files": missing_m3u_files
            },
            "playlist_analysis": playlist_analysis
        })
    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error validating playlists: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": str(e),
            "traceback": error_str
        }), 500


@app.route('/api/correct-track-id', methods=['POST'])
def api_correct_track_id():
    try:
        file_path = request.json.get('file_path')
        new_track_id = request.json.get('new_track_id')

        if not file_path or not new_track_id:
            return jsonify({
                "success": False,
                "message": "Both file_path and new_track_id are required"
            }), 400

        # Check if new track ID exists in database
        with UnitOfWork() as uow:
            track = uow.track_repository.get_by_id(new_track_id)
            if not track:
                return jsonify({
                    "success": False,
                    "message": f"Track ID '{new_track_id}' not found in database"
                }), 400

        # Get existing track ID if any
        old_track_id = None
        try:
            tags = ID3(file_path)
            if 'TXXX:TRACKID' in tags:
                old_track_id = tags['TXXX:TRACKID'].text[0]
        except Exception:
            pass

        # Use the embed_track_id function
        from helpers.file_helper import embed_track_id
        success = embed_track_id(file_path, new_track_id)

        if success:
            return jsonify({
                "success": True,
                "message": f"Successfully updated TrackId from '{old_track_id}' to '{new_track_id}'",
                "old_track_id": old_track_id,
                "new_track_id": new_track_id
            })
        else:
            return jsonify({
                "success": False,
                "message": f"Failed to update TrackId in file: {file_path}"
            }), 500
    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error correcting track ID: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": str(e),
            "traceback": error_str
        }), 500


@app.route('/api/regenerate-playlist', methods=['POST'])
def api_regenerate_playlist():
    try:
        # Get parameters from request
        master_tracks_dir = request.json.get('masterTracksDir') or MASTER_TRACKS_DIRECTORY_SSD
        playlists_dir = request.json.get('playlistsDir')
        playlist_id = request.json.get('playlist_id')
        extended = request.json.get('extended', True)
        force = request.json.get('force', True)

        if not master_tracks_dir:
            return jsonify({
                "success": False,
                "message": "Master tracks directory not specified"
            }), 400

        if not playlists_dir:
            return jsonify({
                "success": False,
                "message": "Playlists directory not specified"
            }), 400

        if not playlist_id:
            return jsonify({
                "success": False,
                "message": "Playlist ID not specified"
            }), 400

        # Always force overwrite when regenerating
        overwrite = True

        # Log detailed information for debugging
        print(f"Regenerating playlist {playlist_id} at {playlists_dir}")
        print(f"Master tracks directory: {master_tracks_dir}")

        # Get the playlist name for more useful messages
        playlist_name = None
        with UnitOfWork() as uow:
            playlist = uow.playlist_repository.get_by_id(playlist_id)
            if playlist:
                playlist_name = playlist.name

        # Import the regenerate function
        from helpers.m3u_helper import sanitize_filename

        # Manually ensure the M3U file is deleted before regeneration if force is specified
        if force and playlist_name:
            safe_name = sanitize_filename(playlist_name, preserve_spaces=True)
            m3u_path = os.path.join(playlists_dir, f"{safe_name}.m3u")
            if os.path.exists(m3u_path):
                try:
                    os.remove(m3u_path)
                    print(f"Forcibly removed existing M3U file: {m3u_path}")
                except Exception as e:
                    print(f"Error removing existing M3U file: {e}")

        # Regenerate the playlist
        result = None
        try:
            from helpers.m3u_helper import regenerate_single_playlist
            result = regenerate_single_playlist(
                playlist_id,
                master_tracks_dir,
                playlists_dir,
                extended=extended,
                overwrite=overwrite
            )
        except Exception as e:
            print(f"Error in regenerate_single_playlist: {e}")
            raise

        # If we're still here, regeneration was successful
        return jsonify({
            "success": True,
            "message": f"Successfully regenerated playlist: {playlist_name or playlist_id}",
            "result": result
        })
    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error regenerating playlist: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": str(e),
            "traceback": error_str
        }), 500


@app.route('/api/remove-track-id', methods=['POST'])
def api_remove_track_id():
    try:
        file_path = request.json.get('file_path')

        if not file_path:
            return jsonify({
                "success": False,
                "message": "file_path is required"
            }), 400

        if not os.path.exists(file_path):
            return jsonify({
                "success": False,
                "message": f"File not found: {file_path}"
            }), 404

        # Get existing track ID if any for reporting
        old_track_id = None
        try:
            from mutagen.id3 import ID3, ID3NoHeaderError
            try:
                tags = ID3(file_path)
                if 'TXXX:TRACKID' in tags:
                    old_track_id = tags['TXXX:TRACKID'].text[0]
                    # Remove the TrackId
                    tags.delall('TXXX:TRACKID')
                    tags.save(file_path)
                else:
                    return jsonify({
                        "success": False,
                        "message": f"No TrackId found in file: {file_path}"
                    }), 400
            except ID3NoHeaderError:
                return jsonify({
                    "success": False,
                    "message": f"No ID3 tags found in file: {file_path}"
                }), 400
        except Exception as e:
            return jsonify({
                "success": False,
                "message": f"Error removing TrackId: {str(e)}"
            }), 500

        return jsonify({
            "success": True,
            "message": f"Successfully removed TrackId '{old_track_id}' from file",
            "old_track_id": old_track_id
        })
    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error removing track ID: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": str(e),
            "traceback": error_str
        }), 500


def run_command(command, wait=True):
    """Run a command and optionally wait for it to complete."""
    print(f"Running: {' '.join(str(c) for c in command)}")

    if wait:
        result = subprocess.run(command, check=False)
        return result.returncode
    else:
        # Run in background
        if sys.platform == 'win32':
            # Windows requires shell=True for background processes
            subprocess.Popen(' '.join(str(c) for c in command), shell=True)
        else:
            # Unix/Linux/Mac
            subprocess.Popen(command)
        return 0


def generate_local_tracks_cache(music_dir, output_dir):
    """Generate local tracks cache file."""
    print("\n=== Generating Local Tracks Cache ===")

    command = [sys.executable, str(SYNC_LOCAL_TRACKS_PATH),
               "--music-dir", music_dir,
               "--output-dir", output_dir]

    return run_command(command)


def start_local_tracks_server(port=DEFAULT_PORT, cache_path=None):
    """Start the local tracks server."""
    print("\n=== Starting Local Tracks Server ===")

    command = [sys.executable, str(LOCAL_TRACKS_SERVER_PATH), "--port", str(port)]
    if cache_path:
        command.extend(["--cache-path", cache_path])

    # Run server in background
    return run_command(command, wait=False)


def main():
    parser = argparse.ArgumentParser(description="Tagify Integration Tools")

    subparsers = parser.add_subparsers(dest="command", help="Command to run")

    # Generate cache command
    cache_parser = subparsers.add_parser("cache", help="Generate local tracks cache")
    cache_parser.add_argument("--music-dir", type=str, default=MASTER_TRACKS_DIRECTORY_SSD,
                              help="Directory containing music files (default from .env)")
    cache_parser.add_argument("--output-dir", type=str, default=LOCAL_TRACKS_CACHE_DIRECTORY,
                              help="Directory to save cache files (default from .env)")

    # Server command
    server_parser = subparsers.add_parser("server", help="Start local tracks server")
    server_parser.add_argument("--port", type=int, default=DEFAULT_PORT,
                               help="Port to run server on (default 8765)")
    server_parser.add_argument("--cache-path", type=str, default=LOCAL_TRACKS_CACHE_DIRECTORY,
                               help="Path to cache directory (default from .env)")

    # All-in-one command
    all_parser = subparsers.add_parser("all", help="Run cache and server in sequence")
    all_parser.add_argument("--music-dir", type=str, default=MASTER_TRACKS_DIRECTORY_SSD,
                            help="Directory containing music files (default from .env)")
    all_parser.add_argument("--cache-dir", type=str, default=LOCAL_TRACKS_CACHE_DIRECTORY,
                            help="Directory to save cache files (default from .env)")
    all_parser.add_argument("--port", type=int, default=DEFAULT_PORT,
                            help="Port to run server on (default 8765)")

    args = parser.parse_args()

    if args.command == "cache":
        generate_local_tracks_cache(args.music_dir, args.output_dir)

    elif args.command == "server":
        start_local_tracks_server(args.port, args.cache_path)
        # Keep script running while server is active
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nServer stopped by user")

    elif args.command == "all":
        # Run all processes in sequence
        print("\n=== Running Tagify Integration ===")

        # 1. Generate cache
        generate_local_tracks_cache(args.music_dir, args.cache_dir)

        # 2. Start server
        start_local_tracks_server(args.port, args.cache_dir)

        # Keep script running while server is active
        print("\n=== Integration Complete ===")
        print(f"Local tracks server running at http://localhost:{args.port}")
        print("Your Spicetify Tagify app can now access your local tracks data")
        print("Press Ctrl+C to stop the server")

        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nServer stopped by user")

    else:
        parser.print_help()


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description="Local Tracks Server")
    parser.add_argument("--port", type=int, default=8765, help="Port to run server on")
    parser.add_argument("--host", type=str, default="127.0.0.1", help="Host to run server on")
    parser.add_argument("--cache-path", type=str, help="Path to the cache file or directory")

    args = parser.parse_args()

    print(f"Starting local tracks server on {args.host}:{args.port}")
    if args.cache_path:
        print(f"Using cache path: {args.cache_path}")

    app.run(host=args.host, port=args.port, debug=True)
