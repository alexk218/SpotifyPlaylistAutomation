#!/usr/bin/env python
import argparse
import json
import os
import subprocess
import sys
import threading
import time
from pathlib import Path

from flask_cors import CORS
from flask import Flask, jsonify, request
from dotenv import load_dotenv
from mutagen.id3 import ID3

from drivers.spotify_client import sync_to_master_playlist, authenticate_spotify
from sql.core.unit_of_work import UnitOfWork

# Load environment variables
load_dotenv()

# Define paths
PROJECT_ROOT = Path(__file__).resolve().parent

# Add project root to Python path for imports
sys.path.insert(0, str(PROJECT_ROOT))

from helpers.file_helper import embed_track_metadata
from helpers.organization_helper import organize_songs_into_m3u_playlists
from helpers.validation_helper import validate_master_tracks
from sql.helpers.db_helper import clear_db, insert_playlists, insert_tracks_and_associations, MASTER_PLAYLIST_ID

app = Flask(__name__)
CORS(app, origins=["https://xpui.app.spotify.com", "https://open.spotify.com", "http://localhost:4000"])
app.config['JSONIFY_PRETTYPRINT_REGULAR'] = True

SCRIPTS_DIR = PROJECT_ROOT / "scripts"
HELPERS_DIR = PROJECT_ROOT / "helpers"

LOCAL_TRACKS_SERVER_PATH = SCRIPTS_DIR / "local_tracks_server.py"
SYNC_LOCAL_TRACKS_PATH = SCRIPTS_DIR / "sync_local_tracks.py"
EMBED_METADATA_SCRIPT = HELPERS_DIR / "file_helper.py"

# Get environment variables
MASTER_TRACKS_DIRECTORY_SSD = os.getenv("MASTER_TRACKS_DIRECTORY_SSD")
LOCAL_TRACKS_CACHE_DIRECTORY = os.getenv("LOCAL_TRACKS_CACHE_DIRECTORY")
MASTER_PLAYLIST_ID = os.getenv("MASTER_PLAYLIST_ID")
DEFAULT_PORT = 8765


@app.route('/')
def get_local_tracks():
    """
    Return the local tracks cache file as JSON.
    This method reads the cache file generated by sync_local_tracks.py
    and returns it to the client.
    """
    try:
        # Default cache file name
        cache_file = "local_tracks_cache.json"

        # Check if we have a specific cache_path from query parameters
        cache_path = request.args.get('cache_path')

        if cache_path and os.path.exists(cache_path):
            # If a specific path was provided and exists, use it
            if os.path.isdir(cache_path):
                # If it's a directory, look for the default cache file inside it
                full_path = os.path.join(cache_path, cache_file)
            else:
                # If it's a file, use it directly
                full_path = cache_path
        elif LOCAL_TRACKS_CACHE_DIRECTORY:
            # Use the environment variable if available
            full_path = os.path.join(LOCAL_TRACKS_CACHE_DIRECTORY, cache_file)
        else:
            # Fallback to a default location relative to the script
            script_dir = Path(__file__).resolve().parent
            full_path = os.path.join(script_dir, "cache", cache_file)

        # Check if the cache file exists
        if not os.path.exists(full_path):
            return jsonify({
                "error": "Cache file not found",
                "message": "Run 'python tagify_integration.py cache' to generate the cache file first."
            }), 404

        # Read the cache file
        with open(full_path, 'r', encoding='utf-8') as f:
            cache_data = json.load(f)

        # Check if the cache data has the expected structure
        if not isinstance(cache_data, dict) or 'tracks' not in cache_data:
            return jsonify({
                "error": "Invalid cache format",
                "message": "The cache file is not in the expected format."
            }), 500

        # Return the cache data
        return jsonify(cache_data)

    except Exception as e:
        return jsonify({
            "error": "Server error",
            "message": str(e)
        }), 500


@app.route('/status')
def get_status():
    return jsonify({
        "status": "running",
        "version": "1.0",
        "env_vars": {
            "MASTER_TRACKS_DIRECTORY_SSD": MASTER_TRACKS_DIRECTORY_SSD,
            "LOCAL_TRACKS_CACHE_DIRECTORY": LOCAL_TRACKS_CACHE_DIRECTORY,
            "MASTER_PLAYLIST_ID": MASTER_PLAYLIST_ID
        }
    })


@app.route('/api/generate-cache', methods=['POST'])
def api_generate_cache():
    try:
        from scripts.sync_local_tracks import generate_cache

        # Get request data with better logging
        request_data = request.get_json()
        print(f"Received request data: {request_data}")

        music_dir = request_data.get('masterTracksDir') if request_data else None
        output_dir = request_data.get('outputDir') if request_data else None

        # Log what we received
        print(f"Music directory from request: {music_dir}")
        print(f"Output directory from request: {output_dir}")

        # Fallback to environment variables if needed
        if not music_dir:
            music_dir = MASTER_TRACKS_DIRECTORY_SSD
            print(f"Using environment variable for music directory: {music_dir}")

        if not output_dir:
            output_dir = LOCAL_TRACKS_CACHE_DIRECTORY
            print(f"Using environment variable for output directory: {output_dir}")

        # Final validation
        if not music_dir:
            return jsonify({
                "success": False,
                "message": "Music directory not specified in request or environment"
            }), 400

        if not output_dir:
            return jsonify({
                "success": False,
                "message": "Output directory not specified in request or environment"
            }), 400

        # Normalize paths (handle backslashes)
        music_dir = os.path.normpath(music_dir)
        output_dir = os.path.normpath(output_dir)

        print(f"Generating cache with music_dir: {music_dir}")
        print(f"Output directory: {output_dir}")

        # Create output directory if it doesn't exist
        os.makedirs(output_dir, exist_ok=True)

        # Now generate the cache
        result = generate_cache(music_dir, output_dir)
        return jsonify({
            "success": True,
            "message": f"Cache generated successfully with {result}",
            "stats": result
        })
    except Exception as e:
        import traceback
        traceback_str = traceback.format_exc()
        print(f"Error in generate-cache: {str(e)}")
        print(traceback_str)
        return jsonify({
            "success": False,
            "message": f"Error: {str(e)}",
            "traceback": traceback_str
        }), 500


@app.route('/api/embed-metadata', methods=['POST'])
def api_embed_metadata():
    master_tracks_dir = request.json.get('masterTracksDir') or MASTER_TRACKS_DIRECTORY_SSD

    if not master_tracks_dir:
        return jsonify({
            "success": False,
            "message": "Master tracks directory not specified in request or environment"
        }), 400

    try:
        # Get list of all files first without making changes
        all_files = []
        total_files = 0
        files_without_id = []

        for root, _, files in os.walk(master_tracks_dir):
            for file in files:
                if not file.lower().endswith('.mp3'):
                    continue

                total_files += 1
                file_path = os.path.join(root, file)

                # Check if file has TrackId
                has_id = False
                try:
                    tags = ID3(file_path)
                    if 'TXXX:TRACKID' in tags:
                        has_id = True
                except Exception:
                    pass

                if not has_id:
                    files_without_id.append(file)

        # Return analysis with all files that need processing
        return jsonify({
            "success": True,
            "message": f"Found {len(files_without_id)} files without TrackId out of {total_files} total files.",
            "needs_confirmation": len(files_without_id) > 0,
            "details": {
                "files_to_process": files_without_id,
                "total_files": total_files
            }
        })
    except Exception as e:
        return jsonify({"success": False, "message": str(e)}), 500


@app.route('/api/generate-m3u', methods=['POST'])
def api_generate_m3u():
    data = request.json
    master_tracks_dir = data.get('masterTracksDir') or MASTER_TRACKS_DIRECTORY_SSD
    playlists_dir = data.get('playlistsDir')

    if not master_tracks_dir:
        return jsonify({
            "success": False,
            "message": "Master tracks directory not specified in request or environment"
        }), 400

    if not playlists_dir:
        return jsonify({
            "success": False,
            "message": "Playlists directory not specified in request"
        }), 400

    try:
        # First, analyze what will be generated
        with UnitOfWork() as uow:
            db_playlists = uow.playlist_repository.get_all()

        # Filter out the MASTER playlist if it exists
        db_playlists = [p for p in db_playlists if p.name.upper() != "MASTER"]

        # Get track counts for each playlist for display
        playlist_stats = []
        for playlist in db_playlists:
            with UnitOfWork() as uow:
                tracks = uow.track_playlist_repository.get_track_ids_for_playlist(playlist.playlist_id)
                track_count = len(tracks)
                playlist_stats.append({
                    'name': playlist.name,
                    'track_count': track_count,
                    'id': playlist.playlist_id
                })

        # Sort playlists by track count (descending)
        playlist_stats.sort(key=lambda x: x['track_count'], reverse=True)

        # Return analysis without making changes
        return jsonify({
            "success": True,
            "message": f"Ready to generate {len(playlist_stats)} M3U playlists.",
            "needs_confirmation": len(playlist_stats) > 0,
            "details": {
                "playlists": playlist_stats,
                "total_playlists": len(playlist_stats),
                "playlists_with_tracks": sum(1 for p in playlist_stats if p['track_count'] > 0)
            }
        })
    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error analyzing M3U generation: {e}")
        print(error_str)
        return jsonify({"success": False, "message": str(e)}), 500


@app.route('/api/validate-tracks', methods=['POST'])
def api_validate_tracks():
    master_tracks_dir = request.json.get('masterTracksDir')

    try:
        result = validate_master_tracks(master_tracks_dir)
        return jsonify({"success": True, "stats": result})
    except Exception as e:
        return jsonify({"success": False, "message": str(e)}), 500


@app.route('/api/sync-to-master', methods=['POST'])
def api_sync_to_master():
    try:
        # Import the function with the fixed implementation
        from drivers.spotify_client import sync_to_master_playlist, authenticate_spotify

        # Get the master playlist ID
        master_playlist_id = request.json.get('master_playlist_id')
        if not master_playlist_id:
            master_playlist_id = MASTER_PLAYLIST_ID

        if not master_playlist_id:
            return jsonify({
                "success": False,
                "message": "Master playlist ID not provided or found in environment"
            }), 400

        spotify_client = authenticate_spotify()

        # This is a long-running operation, so respond immediately
        response = {
            "success": True,
            "message": "Sync to master playlist started. This operation runs in the background and may take several minutes."
        }

        def background_sync():
            try:
                # Use the fixed function
                sync_to_master_playlist(spotify_client, master_playlist_id)
            except Exception as e:
                import traceback
                error_str = traceback.format_exc()
                print(f"Error in background sync: {e}")
                print(error_str)

        thread = threading.Thread(target=background_sync)
        thread.daemon = True
        thread.start()

        return jsonify(response)

    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error starting sync: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": f"Error: {str(e)}"
        }), 500


@app.route('/api/analyze-master-sync', methods=['POST'])
def api_analyze_master_sync():
    try:
        # Import required functions
        from drivers.spotify_client import authenticate_spotify, get_playlist_track_ids

        master_playlist_id = request.json.get('master_playlist_id') or MASTER_PLAYLIST_ID
        if not master_playlist_id:
            return jsonify({
                "success": False,
                "message": "Master playlist ID not provided or found in environment"
            }), 400

        # Authenticate and start analysis
        spotify_client = authenticate_spotify()

        # This is a simplified version of sync_to_master_playlist that just analyzes

        # Get current tracks in MASTER playlist
        master_track_ids = set(get_playlist_track_ids(spotify_client, master_playlist_id, force_refresh=True))

        # Fetch all playlists (excluding forbidden ones)
        from drivers.spotify_client import fetch_playlists
        user_playlists = fetch_playlists(spotify_client, force_refresh=True)

        # Filter playlists safely
        other_playlists = []
        for pl in user_playlists:
            if isinstance(pl, tuple):
                playlist_name = pl[0] if len(pl) > 0 else "Unknown"

                if len(pl) == 2:
                    playlist_id = pl[1]
                elif len(pl) >= 3:
                    playlist_id = pl[2]
                else:
                    continue

                if playlist_id != master_playlist_id:
                    other_playlists.append((playlist_name, playlist_id))

        # Track which songs come from which playlists
        new_tracks_by_playlist = {}

        # Process each playlist
        for playlist_name, playlist_id in other_playlists:
            # Get tracks for this playlist
            playlist_track_ids = get_playlist_track_ids(spotify_client, playlist_id, force_refresh=True)

            # Filter out local files and find tracks not in master
            new_track_ids = []
            for track_id in playlist_track_ids:
                if track_id.startswith('spotify:local:') or track_id.startswith('local_'):
                    continue

                if track_id not in master_track_ids:
                    new_track_ids.append(track_id)

            if not new_track_ids:
                continue

            # Get track details
            playlist_tracks = []
            for j in range(0, len(new_track_ids), 50):
                batch = new_track_ids[j:j + 50]
                try:
                    tracks_info = spotify_client.tracks(batch)
                    for track in tracks_info['tracks']:
                        if track:
                            track_info = {
                                'id': track['id'],
                                'name': track['name'],
                                'artists': ', '.join(artist['name'] for artist in track['artists'])
                            }
                            playlist_tracks.append(track_info)
                except Exception as e:
                    print(f"Error fetching details for track batch: {e}")
                    continue

            if playlist_tracks:
                new_tracks_by_playlist[playlist_name] = playlist_tracks

        # Calculate statistics
        total_tracks = sum(len(tracks) for tracks in new_tracks_by_playlist.values())

        # Include ALL playlists with ALL tracks
        full_playlists = []
        for playlist_name, tracks in sorted(new_tracks_by_playlist.items()):
            sorted_tracks = sorted(tracks, key=lambda x: (x['artists'], x['name']))
            full_playlists.append({
                'name': playlist_name,
                'track_count': len(tracks),
                'tracks': sorted_tracks  # Include ALL tracks
            })

        # Create analysis result
        analysis = {
            'total_tracks_to_add': total_tracks,
            'playlists_with_new_tracks': len(new_tracks_by_playlist),
            'playlists': full_playlists,  # Full list with all tracks
            'needs_confirmation': total_tracks > 0
        }

        return jsonify({
            "success": True,
            "message": f"Analysis complete: {total_tracks} tracks to add from {len(new_tracks_by_playlist)} playlists",
            "master_sync": analysis,
            "needs_confirmation": total_tracks > 0
        })

    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error analyzing master sync: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": f"Error: {str(e)}",
            "traceback": error_str
        }), 500


@app.route('/api/analyze-playlists', methods=['POST'])
def api_analyze_playlists():
    try:
        from helpers.sync_helper import analyze_playlists_changes

        force_refresh = request.json.get('force_refresh', False)

        # Get analysis without executing
        added_count, updated_count, unchanged_count, changes_details = analyze_playlists_changes(
            force_full_refresh=force_refresh
        )

        return jsonify({
            "success": True,
            "message": f"Analysis complete: {added_count} to add, {updated_count} to update, {unchanged_count} unchanged",
            "stats": {
                "added": added_count,
                "updated": updated_count,
                "unchanged": unchanged_count
            },
            "details": {
                "to_add": changes_details['to_add'],
                "to_update": changes_details['to_update']
            },
            "needs_confirmation": added_count > 0 or updated_count > 0
        })
    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error analyzing playlists: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": f"Error: {str(e)}",
            "traceback": error_str
        }), 500


@app.route('/api/analyze-tracks', methods=['POST'])
def api_analyze_tracks():
    try:
        from helpers.sync_helper import analyze_tracks_changes

        master_playlist_id = request.json.get('master_playlist_id') or MASTER_PLAYLIST_ID
        force_refresh = request.json.get('force_refresh', False)

        # Get analysis without executing
        tracks_to_add, tracks_to_update, unchanged_tracks = analyze_tracks_changes(
            master_playlist_id,
            force_full_refresh=force_refresh
        )

        # Include ALL tracks for display
        all_tracks_to_add = []
        for track in tracks_to_add:
            all_tracks_to_add.append({
                "id": track['id'],
                "title": track['title'],
                "artists": track['artists'],
                "album": track['album'],
                "is_local": track.get('is_local', False)
            })

        all_tracks_to_update = []
        for track in tracks_to_update:
            all_tracks_to_update.append({
                "id": track['id'],
                "old_title": track['old_title'],
                "new_title": track['title'],
                "old_artists": track['old_artists'],
                "new_artists": track['artists'],
                "old_album": track['old_album'],
                "new_album": track['album'],
                "is_local": track.get('is_local', False)
            })

        return jsonify({
            "success": True,
            "message": f"Analysis complete: {len(tracks_to_add)} to add, {len(tracks_to_update)} to update, {len(unchanged_tracks)} unchanged",
            "stats": {
                "added": len(tracks_to_add),
                "updated": len(tracks_to_update),
                "unchanged": len(unchanged_tracks)
            },
            "details": {
                "all_items_to_add": all_tracks_to_add,  # Full list for pagination
                "to_add": all_tracks_to_add[:20],  # First 20 for immediate display
                "to_add_total": len(tracks_to_add),
                "all_items_to_update": all_tracks_to_update,  # Full list for pagination
                "to_update": all_tracks_to_update[:20],  # First 20 for immediate display
                "to_update_total": len(tracks_to_update)
            },
            "needs_confirmation": len(tracks_to_add) > 0 or len(tracks_to_update) > 0
        })
    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error analyzing tracks: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": f"Error: {str(e)}",
            "traceback": error_str
        }), 500


@app.route('/api/analyze-associations', methods=['POST'])
def api_analyze_associations():
    try:
        # We need to create a custom function for this
        from helpers.sync_helper import analyze_track_playlist_associations

        master_playlist_id = request.json.get('master_playlist_id') or MASTER_PLAYLIST_ID
        force_refresh = request.json.get('force_refresh', False)

        # A custom function to get analysis without executing
        changes = analyze_track_playlist_associations(
            master_playlist_id,
            force_full_refresh=force_refresh
        )

        # Format changes for display
        formatted_changes = {
            "tracks_with_changes": len(changes['tracks_with_changes']),
            "associations_to_add": changes['associations_to_add'],
            "associations_to_remove": changes['associations_to_remove'],
            "samples": changes['samples'][:20]  # First 20 changes for display
        }

        return jsonify({
            "success": True,
            "message": f"Analysis complete: {changes['associations_to_add']} to add, {changes['associations_to_remove']} to remove, affecting {len(changes['tracks_with_changes'])} tracks",
            "stats": changes['stats'],
            "details": formatted_changes,
            "needs_confirmation": changes['associations_to_add'] > 0 or changes['associations_to_remove'] > 0
        })
    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error analyzing associations: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": f"Error: {str(e)}",
            "traceback": error_str
        }), 500


# Modified sync-database to handle the confirmation flow
# 2. Fix the sync-database route
@app.route('/api/sync-database', methods=['POST'])
def api_sync_database():
    from helpers.sync_helper import (
        sync_playlists_incremental,
        sync_master_tracks_incremental,
        sync_track_playlist_associations
    )

    data = request.json
    action = data.get('action', 'all')
    force_refresh = data.get('force_refresh', False)
    is_confirmed = data.get('confirmed', False)

    try:
        if action == 'clear':
            from sql.helpers.db_helper import clear_db
            clear_db()
            return jsonify({"success": True, "message": "Database cleared successfully"})

        elif action == 'playlists':
            # If not confirmed, return the analysis result instead
            if not is_confirmed:
                # Call analyze endpoint and return that result
                from flask import redirect
                return redirect('/api/analyze-playlists', code=307)  # 307 preserves POST method

            # Otherwise, proceed with execution
            added, updated, unchanged = sync_playlists_incremental(
                force_full_refresh=force_refresh,
                auto_confirm=True  # Skip confirmation prompt in the function
            )
            return jsonify({
                "success": True,
                "message": f"Playlists synced: {added} added, {updated} updated, {unchanged} unchanged",
                "stats": {
                    "added": added,
                    "updated": updated,
                    "unchanged": unchanged
                }
            })

        elif action == 'tracks':
            # If not confirmed, return the analysis result instead
            if not is_confirmed:
                # Call analyze endpoint and return that result
                from flask import redirect
                return redirect('/api/analyze-tracks', code=307)

            # Otherwise, proceed with execution
            master_playlist_id = data.get('master_playlist_id') or MASTER_PLAYLIST_ID
            added, updated, unchanged = sync_master_tracks_incremental(
                master_playlist_id,
                force_full_refresh=force_refresh,
                auto_confirm=True
            )
            return jsonify({
                "success": True,
                "message": f"Tracks synced: {added} added, {updated} updated, {unchanged} unchanged",
                "stats": {
                    "added": added,
                    "updated": updated,
                    "unchanged": unchanged
                }
            })

        elif action == 'associations':
            # If not confirmed, return the analysis result instead
            if not is_confirmed:
                # Call analyze endpoint and return that result
                from flask import redirect
                return redirect('/api/analyze-associations', code=307)

            # Otherwise, proceed with execution
            master_playlist_id = data.get('master_playlist_id') or MASTER_PLAYLIST_ID
            stats = sync_track_playlist_associations(
                master_playlist_id,
                force_full_refresh=force_refresh,
                auto_confirm=True
            )
            return jsonify({
                "success": True,
                "message": f"Associations synced: {stats['associations_added']} added, {stats['associations_removed']} removed",
                "stats": stats
            })

        elif action == 'all':
            # For 'all', we'll use a different approach - analyze in sequence and return all results
            if not is_confirmed:
                # Analyze all operations
                master_playlist_id = data.get('master_playlist_id') or MASTER_PLAYLIST_ID

                # 1. Analyze playlists
                from helpers.sync_helper import analyze_playlists_changes
                playlists_added, playlists_updated, playlists_unchanged, playlists_details = analyze_playlists_changes(
                    force_full_refresh=force_refresh
                )

                # 2. Analyze tracks
                from helpers.sync_helper import analyze_tracks_changes
                tracks_to_add, tracks_to_update, tracks_unchanged = analyze_tracks_changes(
                    master_playlist_id,
                    force_full_refresh=force_refresh
                )

                # Format tracks for display - ALL tracks, not just samples
                all_tracks_to_add = []
                for track in tracks_to_add:
                    all_tracks_to_add.append({
                        "artists": track['artists'],
                        "title": track['title'],
                        "is_local": track.get('is_local', False)
                    })

                all_tracks_to_update = []
                for track in tracks_to_update:
                    all_tracks_to_update.append({
                        "old_artists": track['old_artists'],
                        "old_title": track['old_title'],
                        "artists": track['artists'],
                        "title": track['title'],
                        "is_local": track.get('is_local', False)
                    })

                # 3. Analyze associations
                from helpers.sync_helper import analyze_track_playlist_associations
                associations_changes = analyze_track_playlist_associations(
                    master_playlist_id,
                    force_full_refresh=force_refresh
                )

                # Prepare the complete analysis result with FULL data
                all_analyses = {
                    "playlists": {
                        "added": playlists_added,
                        "updated": playlists_updated,
                        "unchanged": playlists_unchanged,
                        "details": playlists_details  # Already has full lists
                    },
                    "tracks": {
                        "added": len(tracks_to_add),
                        "updated": len(tracks_to_update),
                        "unchanged": len(tracks_unchanged),
                        "to_add_sample": all_tracks_to_add[:20],  # First 20 for immediate display
                        "all_tracks_to_add": all_tracks_to_add,  # Full list for pagination
                        "to_add_total": len(tracks_to_add),
                        "to_update_sample": all_tracks_to_update[:20],  # First 20 for immediate display
                        "all_tracks_to_update": all_tracks_to_update,  # Full list for pagination
                        "to_update_total": len(tracks_to_update)
                    },
                    "associations": {
                        **associations_changes,
                        "all_changes": associations_changes["samples"]  # Full list of changes
                    }
                }

                # Determine if we need confirmation
                needs_confirmation = (
                        playlists_added > 0 or
                        playlists_updated > 0 or
                        len(tracks_to_add) > 0 or
                        len(tracks_to_update) > 0 or
                        associations_changes['associations_to_add'] > 0 or
                        associations_changes['associations_to_remove'] > 0
                )

                return jsonify({
                    "success": True,
                    "message": "Analysis complete",
                    "analyses": all_analyses,
                    "needs_confirmation": needs_confirmation
                })

            # Handle the execution case for 'all' when confirmed
            # Add execution code here for when action='all' and is_confirmed=True
            # For now, let's return a message that this isn't implemented yet
            return jsonify({
                "success": False,
                "message": "Confirmation execution for 'all' action not implemented yet"
            })

        else:
            return jsonify({"success": False, "message": "Invalid action"}), 400
    except Exception as e:
        import traceback
        error_str = traceback.format_exc()
        print(f"Error in sync_database: {e}")
        print(error_str)
        return jsonify({
            "success": False,
            "message": f"Error: {str(e)}",
            "traceback": error_str
        }), 500


def run_command(command, wait=True):
    """Run a command and optionally wait for it to complete."""
    print(f"Running: {' '.join(str(c) for c in command)}")

    if wait:
        result = subprocess.run(command, check=False)
        return result.returncode
    else:
        # Run in background
        if sys.platform == 'win32':
            # Windows requires shell=True for background processes
            subprocess.Popen(' '.join(str(c) for c in command), shell=True)
        else:
            # Unix/Linux/Mac
            subprocess.Popen(command)
        return 0


def generate_local_tracks_cache(music_dir, output_dir):
    """Generate local tracks cache file."""
    print("\n=== Generating Local Tracks Cache ===")

    command = [sys.executable, str(SYNC_LOCAL_TRACKS_PATH),
               "--music-dir", music_dir,
               "--output-dir", output_dir]

    return run_command(command)


def start_local_tracks_server(port=DEFAULT_PORT, cache_path=None):
    """Start the local tracks server."""
    print("\n=== Starting Local Tracks Server ===")

    command = [sys.executable, str(LOCAL_TRACKS_SERVER_PATH), "--port", str(port)]
    if cache_path:
        command.extend(["--cache-path", cache_path])

    # Run server in background
    return run_command(command, wait=False)


def main():
    parser = argparse.ArgumentParser(description="Tagify Integration Tools")

    subparsers = parser.add_subparsers(dest="command", help="Command to run")

    # Generate cache command
    cache_parser = subparsers.add_parser("cache", help="Generate local tracks cache")
    cache_parser.add_argument("--music-dir", type=str, default=MASTER_TRACKS_DIRECTORY_SSD,
                              help="Directory containing music files (default from .env)")
    cache_parser.add_argument("--output-dir", type=str, default=LOCAL_TRACKS_CACHE_DIRECTORY,
                              help="Directory to save cache files (default from .env)")

    # Server command
    server_parser = subparsers.add_parser("server", help="Start local tracks server")
    server_parser.add_argument("--port", type=int, default=DEFAULT_PORT,
                               help="Port to run server on (default 8765)")
    server_parser.add_argument("--cache-path", type=str, default=LOCAL_TRACKS_CACHE_DIRECTORY,
                               help="Path to cache directory (default from .env)")

    # All-in-one command
    all_parser = subparsers.add_parser("all", help="Run cache and server in sequence")
    all_parser.add_argument("--music-dir", type=str, default=MASTER_TRACKS_DIRECTORY_SSD,
                            help="Directory containing music files (default from .env)")
    all_parser.add_argument("--cache-dir", type=str, default=LOCAL_TRACKS_CACHE_DIRECTORY,
                            help="Directory to save cache files (default from .env)")
    all_parser.add_argument("--port", type=int, default=DEFAULT_PORT,
                            help="Port to run server on (default 8765)")

    args = parser.parse_args()

    if args.command == "cache":
        generate_local_tracks_cache(args.music_dir, args.output_dir)

    elif args.command == "server":
        start_local_tracks_server(args.port, args.cache_path)
        # Keep script running while server is active
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nServer stopped by user")

    elif args.command == "all":
        # Run all processes in sequence
        print("\n=== Running Tagify Integration ===")

        # 1. Generate cache
        generate_local_tracks_cache(args.music_dir, args.cache_dir)

        # 2. Start server
        start_local_tracks_server(args.port, args.cache_dir)

        # Keep script running while server is active
        print("\n=== Integration Complete ===")
        print(f"Local tracks server running at http://localhost:{args.port}")
        print("Your Spicetify Tagify app can now access your local tracks data")
        print("Press Ctrl+C to stop the server")

        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nServer stopped by user")

    else:
        parser.print_help()


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description="Local Tracks Server")
    parser.add_argument("--port", type=int, default=8765, help="Port to run server on")
    parser.add_argument("--host", type=str, default="127.0.0.1", help="Host to run server on")
    parser.add_argument("--cache-path", type=str, help="Path to the cache file or directory")

    args = parser.parse_args()

    print(f"Starting local tracks server on {args.host}:{args.port}")
    if args.cache_path:
        print(f"Using cache path: {args.cache_path}")

    app.run(host=args.host, port=args.port, debug=True)
